# Table of Contents

1. [Bring your own virtual agent](#byova-section)
2. [Media Forking](#media-forking-section)


# Bring your own Virtual Agent <a name="byova-section"></a>

The Bring Your Own Virtual Agent Initiative empowers Developers and AI vendors to seamlessly integrate external conversational interface(s) with Webex Contact Center IVR.

## What is a Voice Virtual Agent?

To summarize, the voice virtual agent connects to a caller on a voice call and performs the following actions:
   - Transcribes the caller's **speech to text** for AI processing.
   - Utilizes **Natural Language Understanding** to identify the caller's intent.
   - Maps the identified **intent** to an existing workflow (OR) uses **Generative AI** to create a text response.
   - Converts the generated **text to speech** which is then prompted to the caller back.
   - For escalated calls, provides the human agent with context by supplying the virtual agent's transcript or a summary.
   - Post-call data, including Total Call Handled Time, Call Resolution, Caller Intent, etc. is available in Webex Analyzer.

![VA-flow](./src/main/resources/images/VACallFlowWithEscalation.jpg)

*Fig 1: A sample virtual agent call that is escalated to a human agent*

## Dialog Connector Simulator
The Dialog Connector Simulator is a sample code that demonstrates how to integrate an external conversational interface with Webex Contact Center IVR.

Refer to the [Dialog Connector Simulator Sample Code](https://github.com/CiscoDevNet/webex-contact-center-ai-sample-code/tree/main/provider-api/dialog-connector-simulator).
For the interface definition see `src/main/proto/com/cisco/wcc/ccai/media/v1/VoiceVirtualAgent.proto`.


### Onboarding Steps for Using the Dialog Connector Simulator
![VA-flow](./src/main/resources/images/VAProvisioning.jpg)

*Fig 2: Architectural Diagram for provisioning a Virtual Agent*

To use the Dialog Connector Simulator, follow these onboarding steps(for CASPRx providers):

1. **Integration Setup**:
    - Use the Webex Contact Center Control Hub to create an integration **Control Hub -> Contact Center -> Integrations**
    - **Link to integrations** https://admin.webex.com/wxcc/integrations
    - In the Connector Tab, set up the provider's Connector credentials.
      ![VA-flow](./src/main/resources/images/VAConnectors.jpg)
   
      *Fig 3: Setup Virtual Agent Connectors on the Webex Admin Portal*
2. **AI Configuration**:
    - In the Features Tab, create a Contact Center AI Configuration. This configuration is represented by a `configId` and defines the credentials and features to be used.
      ![VA-flow](./src/main/resources/images/VACCAIConfig.jpg)
   
      *Fig 4: Setup a Contact Center AI Configuration entity that connects Webex CC with the external AI service platform*
   
3. **Flow Creation**:
    - Create a flow with the Virtual Agent Voice Activity and use the above created AI Configuration in the Flow Control UI.
      ![VA-flow](./src/main/resources/images/VAFlowBuilder.jpg)
      
   *Fig 5: Use the “Virtual Agent Activity” in the flow designer to select the virtual agent and configure the routing logic of your workflow.*
4. **EntryPoint Mapping**:
    - Map the EntryPoint to the newly created flow (EntryPoint -> Routing Strategy -> Flow).

After these steps, the Webex Contact Center (WxCC) will orchestrate the call to a specific provider based on the configuration details.

For Non-CASPRx providers steps are below-
1. **Service App creation and authorization**:-
- Service app with spark-admin:dataSource_read/dataSource_write scopes has to be created using dev-portal
![image](https://github.com/user-attachments/assets/e9fa0edc-6364-4c49-b5a1-21b8f139b10c)
Respective schema(voice virtual agent for BYoVA) has to be selected along with the data exchange domain. In the domain we need to mention the dialogue connector simulator or endpoint at which exchange has to happen.
![image](https://github.com/user-attachments/assets/04b7e964-c7c5-4e9d-a31e-29ed32073958)
After app creation, it has to be submitted to customer org admin for authorization-
![image](https://github.com/user-attachments/assets/6740d22c-24d7-4685-b407-8c62a24362b4)

2. **Org admin authorization and data source registration**:-
   Org admin needs to authorize the apps by going to "apps" section of control hub and validating the fields.
   Provider needs to register the data source using authorized service app's token(which can be generated by going to your service app and generate token for the customer org by selecting the org from drop down on developer portal.

3. **Config creation**:-
   Once the service app is authorized and data source is regsitered, Org admin will then create a config by going to the features section-
   ![image](https://github.com/user-attachments/assets/09cefda0-94f3-423a-b148-cae59d97eacc)

4. **Flow Creation**:
    - Create a flow with the Virtual Agent Voice Activity and use the above created AI Configuration in the Flow Control UI.
      ![VA-flow](./src/main/resources/images/VAFlowBuilder.jpg)
      
   *Fig 5: Use the “Virtual Agent Activity” in the flow designer to select the virtual agent and configure the routing logic of your workflow.*
   
5. **EntryPoint Mapping**:
    - Map the EntryPoint to the newly created flow (EntryPoint -> Routing Strategy -> Flow).



### Prerequisites for Setting Up the Connector

#### Audio Configuration
- Audio Format Supported: _**wav**_
- Audio Sampling Rate: _**16kHz/8KHz**_
- Language: _**en-US**_
- Encoding Format: _**Linear16/ulaw**_
- Please note, we only support wav or raw audio files, 8/16kHz bit rate, single channel

#### Authentication (Coming Soon)
Details about this section will be provided in a future update.

#### List Bot API for Dialog Connector Simulator (Optional)
Each Provider endpoint is recommended to implement an API to return a list of configured bots to be used in
Flow builder to decide the bot to be used during the call flow with the Customer.
The API should return the list of bots configured in the system.
Refer to the ListVirtualAgents API in the ccai-api.proto file.

#### Serviceability
Each Provider endpoint should expose APIs to monitor the health of the endpoint. The APIs should return the status of the service.
Refer to the Check API in the health.proto file.

## Dialog Connector Application Development
### Code Overview
This sample code offers an overview of the various methods and messages used when the Dialog Connector interacts with
the Webex CC VA Client Application.

Here,the Dialog Connector represents a **gRPC Server Application**(see `src/main/java/com/cisco/wccai/grpc/server/GrpcServer.java`) that listens for incoming requests from the
Webex CC VA Client Application which is a **gRPC Client Application**(see `src/main/java/com/cisco/wccai/grpc/client/VoiceVAClient.java`).



### Development Environment Commands
1. Install Java 17.
Verify the Installation by opening a new terminal and run:

    `java -version`
2. Compile Protobuf Definitions: This will generate java classes under target/generated-sources/protobuf/grpc-java and target/generated-sources/protobuf/java.
    
    `cd webex-contact-center-byova-sample-code/provider-api/dialog-connector-simulator`

    `mvn clean compile`
3. Build the Main Application:

   `mvn clean install`

### Detailed Flow with Sequence Diagram
#### Step 1. Start of Conversation
1. The Dialog Connector will start up as a **gRPC Server Application** (`run GrpcServer.java`).
2. The Webex CC Virtual Agent (VA) Client Application will start up as a **gRPC Client**(`run ConnectorClientVA.java`) and open a secure gRPC connection with the Server Application.
3. When a caller calls, the Client Application signals to the Dialog Connector to start the conversation by creating a new conversation (`conversation_id`) and sending a `VoiceVARequest` to the Server Application with `EventType: SESSION_START`. The `conversation_id` is used for the entire conversation between the Caller (Webex CC VA Client Application) and Virtual Agent (Server Application). The request is sent without any audio data.
4. `EventType: SESSION_START` can be used by the connector to start the session with its AI Service and return a response back to the Client using `ViceVAResponse`. It could contain response payloads, prompts, NLU data, and input mode for handling the next interactions from the Caller. Prompts contain the audio which needs to be played to the Caller. It can return one or multiple prompts in a response. Prompts are played one after another at the client side in the sequence of receiving.

   <img src="./src/main/resources/images/BYOVASampleCodeSequenceDiagramStep1.jpg" alt="Description" style="box-shadow: 5px 4px 8px rgba(0, 0, 0, 0.1); border: 1px solid #ccc; border-radius: 4px;">

#### Step 2. Continue the Conversation Between the Caller and Virtual Agent
1. The Client Application, on receiving the prompt, plays it to the Caller and invokes the next dialog based on the input mode received in the response.
2. **Input Mode** indicates the type of input expected from the Caller. It can be `dtmf` only, `voice` only, or `dtmf_and_voice` both.
    - If the input mode is `dtmf`, the Client Application will wait for the DTMF input from the Caller.
    - If the input mode is `voice`, the Client Application will wait for the voice input from the Caller.
    - If the input mode is `dtmf_and_voice`, the Client Application will start streaming voice input from the Caller.
3. On detecting voice, the Server sends a `EVENT_START_OF_INPUT` to the Client Application to indicate that the Caller is providing voice input and to stop playing the prompt.
4. Once the Caller finishes speaking, the Server detects silence and sends a `EVENT_END_OF_INPUT` to the Client Application to indicate that the Caller has finished speaking.
5. The Server processes the Caller's request and then sends back a `VoiceVAResponse` to the Client Application with a new set of prompts, NLU data, and input mode for handling the next interactions.

   <img src="./src/main/resources/images/BYOVASampleCodeSequenceDiagramStep2.jpg" alt="Description" style="box-shadow: 5px 4px 8px rgba(0, 0, 0, 0.1); border: 1px solid #ccc; border-radius: 4px;">

#### Step 3. Stop the Conversation
1. When the conversation ends between the Caller and Virtual Agent, the Caller can disconnect the call.
    - The Client Application sends a `StreamingAnalyzeContentRequest` to the Server Application with `EventType: SESSION_END`.
    - `EventType: SESSION_END` can be used by the Server Application to close the session with its AI Service and return a response back to the Client using `VoiceVAResponse`.
2. Similarly, the Virtual Agent can disconnect the call as well using any of the below Exit events as part of `StreamingAnalyzeContentResponse`.
    - **Call End Event**: Sent when the Server Application wants to disconnect the call from the Virtual Agent side.
    - **Agent Transfer Event**: Sent when the Virtual Agent wants to transfer the call to a human agent.
    - **Custom Event**: Sent when the Virtual Agent wants to return control to the calling application flow. It can pass metadata which will contain the context needed for the Client flow.
3. The conversation is complete.
4. The Server Application can close the gRPC connection with the Client Application.

   <img src="./src/main/resources/images/BYOVASampleCodeSequenceDiagramStep3.jpg" alt="Description" style="box-shadow: 5px 4px 8px rgba(0, 0, 0, 0.1); border: 1px solid #ccc; border-radius: 4px;">



# Glossary
* **Prompts**: The API response will provide the barge-in status of the prompts to be played. Each prompt will indicate if it is barge-in enabled or disabled. The first barge-in enabled prompt in the sequence will make all subsequent prompts barge-in enabled. The Client will play the non-barge-in prompts independently.
* **Prompt Duration**: The Client will also need to set the total duration of barge-in enabled prompts so that the recognizer can wait for this duration.
* **Barge-In**: When the Client receives the START_OF_INPUT event, it will act as an indicator for the Client to barge-in the prompt and continue streaming.
* **Timeout**:  The recognizer will wait for user input based on the timer configured after the prompt finishes. If the user does not provide any input in this duration, the input will time out, resulting in a no-input event.
* **END_OF_INPUT**: If the user has finished speaking and has taken a pause or has entered all the digits, the Client will receive the END_OF_INPUT event, indicating to the Client to stop streaming.

# Media Forking <a name="media-forking-section"></a>

This feature allows customers to access the media which is the real time interaction between the human agent and the caller in the Webex Contact Center.

## Dialog Connector Simulator for Media Forking

The Dialog Connector Simulator is a sample code that demonstrates how to receive the media from the Webex Contact Center and do the further processing.

Refer to the [Dialog Connector Simulator Sample Code](https://github.com/CiscoDevNet/webex-contact-center-provider-sample-code/tree/main/media-service-api/dialog-connector-simulator).
For the interface definition see `src/main/proto/com/cisco/wcc/ccai/media/v1/conversationaudioforking.proto`.

The proto has a bidirectional streaming RPC where the client(Webex contact center) streams the audio during the call and server(customer/partner) sends acknowledgement once when onComplete() is received.

### Code Overview

This sample code offers an overview of the various methods and messages used when the when Webex contact center interacts with the dialog connector simulator server.

Here,the dialog connector simulator server represents a **gRPC Server Application**(see `src/main/java/com/cisco/wccai/grpc/server/GrpcServer.java`) that listens for incoming requests from the Webex Contact Center.

### Development Environment Commands
1. Install Java 17.
   Verify the Installation by opening a new terminal and run:

   `java -version`
2. Compile Protobuf Definitions: This will generate java classes under target/generated-sources/protobuf/grpc-java and target/generated-sources/protobuf/java.

   `cd webex-contact-center-provider-sample-code/media-service-api/dialog-connector-simulator`

   `mvn clean compile`
3. Build the Main Application:

   `mvn clean install`
4. The Dialog Connector will start up as a **gRPC Server Application** (`run GrpcServer.java`).

### Detailed Flow with Sequence Diagram

<img src="./src/main/resources/images/media-forking-sequence.jpg" alt="Description" style="box-shadow: 5px 4px 8px rgba(0, 0, 0, 0.1); border: 1px solid #ccc; border-radius: 4px;">

> **_NOTE:_** The customer using this feature would write the logic to do further processing of the media received based on their requirements. The simulator code above does not do any further processing with the audio received. 


